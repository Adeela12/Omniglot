{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "one-shot-learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCXmgic3oONq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f879fe66-bd76-40c5-8b18-ba0fec16a505"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9A5I3g2oTDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "3580029b-1c20-4bfc-caa4-bb487c1ac5f1"
      },
      "source": [
        "!nvidia-smi\n",
        "%cd /content/drive/My Drive/omniglot\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 14 08:48:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "/content/drive/My Drive/omniglot\n",
            " images_background\n",
            " images_background.zip\n",
            "'images_background.zip (Unzipped Files)'\n",
            "'images_background.zip (Unzipped Files) (1)'\n",
            " images_evaluation\n",
            " images_evaluation.zip\n",
            "'images_evaluation.zip (Unzipped Files)'\n",
            "'images_evaluation.zip (Unzipped Files) (1)'\n",
            " one-shot-learning.ipynb\n",
            " siameseNet-batchnorm50.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P_n-LWrZ0KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from os import walk\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3oSjmgid55a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#root_dir = './images_background/'\n",
        "root_dir = './images_evaluation/'\n",
        "categories = [[folder, os.listdir(root_dir + folder)] for folder in os.listdir(root_dir)  if not folder.startswith('.') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XeQEOJHeCSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OmniglotDataset(Dataset):\n",
        "    def __init__(self, categories, root_dir, setSize, transform=None):\n",
        "        self.categories = categories\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.setSize = setSize\n",
        "    def __len__(self):\n",
        "        return self.setSize\n",
        "    def __getitem__(self, idx):\n",
        "        img1 = None\n",
        "        img2 = None\n",
        "        label = None\n",
        "        if idx % 2 == 0: # select the same character for both images\n",
        "            category = random.choice(categories)\n",
        "            character = random.choice(category[1])\n",
        "            imgDir = root_dir + category[0] + '/' + character\n",
        "            img1Name = random.choice(os.listdir(imgDir))\n",
        "            img2Name = random.choice(os.listdir(imgDir))\n",
        "            img1 = Image.open(imgDir + '/' + img1Name)\n",
        "            img2 = Image.open(imgDir + '/' + img2Name)\n",
        "            # print(imgDir+'/'+img1Name)\n",
        "            # print(imgDir+'/'+img2Name)\n",
        "            label = 1.0\n",
        "        else: # select a different character for both images\n",
        "            category1, category2 = random.choice(categories), random.choice(categories)\n",
        "            category1, category2 = random.choice(categories), random.choice(categories)\n",
        "            character1, character2 = random.choice(category1[1]), random.choice(category2[1])\n",
        "            imgDir1, imgDir2 = root_dir + category1[0] + '/' + character1, root_dir + category2[0] + '/' + character2\n",
        "            img1Name = random.choice(os.listdir(imgDir1))\n",
        "            img2Name = random.choice(os.listdir(imgDir2))\n",
        "            while img1Name == img2Name:\n",
        "                img2Name = random.choice(os.listdir(imgDir2))\n",
        "            label = 0.0\n",
        "            img1 = Image.open(imgDir1 + '/' + img1Name)\n",
        "            img2 = Image.open(imgDir2 + '/' + img2Name)\n",
        "#         plt.imshow(img1)\n",
        "        if self.transform:\n",
        "            img1 = self.transform(img1)\n",
        "            img2 = self.transform(img2)\n",
        "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE8-c5g2fJEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NWayOneShotEvalSet(Dataset):\n",
        "    def __init__(self, categories, root_dir, setSize, numWay, transform=None):\n",
        "        self.categories = categories\n",
        "        self.root_dir = root_dir\n",
        "        self.setSize = setSize\n",
        "        self.numWay = numWay\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return self.setSize\n",
        "    def __getitem__(self, idx):\n",
        "        # find one main image\n",
        "        category = random.choice(categories)\n",
        "        character = random.choice(category[1])\n",
        "        imgDir = root_dir + category[0] + '/' + character\n",
        "        imgName = random.choice(os.listdir(imgDir))\n",
        "        mainImg = Image.open(imgDir + '/' + imgName)\n",
        "        # print(imgDir + '/' + imgName)\n",
        "        if self.transform:\n",
        "            mainImg = self.transform(mainImg)\n",
        "        \n",
        "        # find n numbers of distinct images, 1 in the same set as the main\n",
        "        testSet = []\n",
        "        label = np.random.randint(self.numWay)\n",
        "        for i in range(self.numWay):\n",
        "            testImgDir = imgDir\n",
        "            testImgName = ''\n",
        "            if i == label:\n",
        "                testImgName = random.choice(os.listdir(imgDir))\n",
        "            else:\n",
        "                testCategory = random.choice(categories)\n",
        "                testCharacter = random.choice(testCategory[1])\n",
        "                testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
        "                while testImgDir == imgDir:\n",
        "                    testImgDir = root_dir + testCategory[0] + '/' + testCharacter\n",
        "                testImgName = random.choice(os.listdir(testImgDir))\n",
        "            testImg = Image.open(testImgDir + '/' + testImgName)\n",
        "            if self.transform:\n",
        "                testImg = self.transform(testImg)\n",
        "            testSet.append(testImg)\n",
        "        # plt.imshow()\n",
        "        return mainImg, testSet, torch.from_numpy(np.array([label], dtype = int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22r2d2YkfSUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataSize = 10000 # self-defined dataset size\n",
        "TRAIN_PCT = 0.8 # percentage of entire dataset for training\n",
        "train_size = int(dataSize * TRAIN_PCT)\n",
        "val_size = dataSize - train_size\n",
        "\n",
        "transformations = transforms.Compose(\n",
        "    [transforms.ToTensor()]) \n",
        "\n",
        "omniglotDataset = OmniglotDataset(categories, root_dir, dataSize, transformations)\n",
        "train_set, val_set = random_split(omniglotDataset, [train_size, val_size])\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, num_workers=16)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, num_workers=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13vNYQZ6fW78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testSize = 5000 \n",
        "numWay = 20\n",
        "test_set = NWayOneShotEvalSet(categories, root_dir, testSize, numWay, transformations)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 1, num_workers = 2, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLeAG_IsfZ-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "935ad81c-be52-40e2-cbb2-e2c508f1d826"
      },
      "source": [
        "count0 = 0\n",
        "count1 = 0\n",
        "for img1, img2, label in train_loader:\n",
        "    print()\n",
        "    if label[0] == 1.0:\n",
        "        print(img1[0])\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(img1[0][0])\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(img2[0][0])\n",
        "        # print(label)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
            "         [1., 1., 1.,  ..., 1., 1., 1.]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mQlWqq_fdXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "5f4bd6e8-a92d-40f7-d8f2-9d96984f4dc7"
      },
      "source": [
        "count = 0\n",
        "for mainImg, imgset, label in test_loader:\n",
        "    # print(len(imgset))\n",
        "    # print(label)\n",
        "    # print(imgset.shape)\n",
        "    if label != 1:\n",
        "        for count, img in enumerate(imgset):\n",
        "          plt.subplot(1, len(imgset)+1, count+1)\n",
        "          plt.imshow(img[0][0])\n",
        "          # print(img.shape)\n",
        "        print(mainImg.shape)\n",
        "        plt.subplot(1, len(imgset)+1, len(imgset)+1)\n",
        "        plt.imshow(mainImg[0][0])\n",
        "        count += 1\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 105, 105])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 21 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5DYHvlsEQWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI7ekWLUEVHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Koch et al.\n",
        "        # Conv2d(input_channels, output_channels, kernel_size)\n",
        "        self.conv1 = nn.Conv2d(1, 64, 10) \n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)  \n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fcOut = nn.Linear(4096, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # VGG16\n",
        "        # # dataiter = iter(train_loader)\n",
        "        # # img1, img2, label = dataiter.next()\n",
        "        # # print(img1.shape)\n",
        "        # self.conv11 = nn.Conv2d(1, 64, 3) \n",
        "        # self.conv12 = nn.Conv2d(64, 64, 3)  \n",
        "        # self.conv21 = nn.Conv2d(64, 128, 3)\n",
        "        # self.conv22 = nn.Conv2d(128, 128, 3)\n",
        "        # self.conv31 = nn.Conv2d(128, 256, 3) \n",
        "        # self.conv32 = nn.Conv2d(256, 256, 3)  \n",
        "        # self.conv33 = nn.Conv2d(256, 256, 3)\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        # self.fc1 = nn.Linear(256 * 8 * 8, 4096)\n",
        "        # self.fc2 = nn.Linear(4096, 4096)\n",
        "        # self.fcOut = nn.Linear(4096, 1)\n",
        "        # self.sigmoid = nn.Sigmoid()\n",
        "        # # x = self.conv11(img1)\n",
        "        # # x = self.conv12(x)\n",
        "        # # x = self.pool(x)\n",
        "        # # x = self.conv21(x)\n",
        "        # # x = self.conv22(x)\n",
        "        # # x = self.pool(x)\n",
        "        # # x = self.conv31(x)\n",
        "        # # x = self.conv32(x)\n",
        "        # # x = self.conv33(x)\n",
        "        # # x = self.pool(x)\n",
        "        # # print(x.shape)\n",
        "    \n",
        "    def convs(self, x):\n",
        "\n",
        "        # Koch et al.\n",
        "        # out_dim = in_dim - kernel_size + 1  \n",
        "        #1, 105, 105\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # 64, 96, 96\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 64, 48, 48\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        # 128, 42, 42\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 128, 21, 21\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        # 128, 18, 18\n",
        "        x = F.max_pool2d(x, (2,2))\n",
        "        # 128, 9, 9\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        # 256, 6, 6\n",
        "        return x\n",
        "\n",
        "        # VGG16\n",
        "        # x = F.relu(self.conv11(x))\n",
        "        # x = F.relu(self.conv12(x))\n",
        "        # x = F.max_pool2d(x, (2,2))\n",
        "        # x = F.relu(self.conv21(x))\n",
        "        # x = F.relu(self.conv22(x))\n",
        "        # x = F.max_pool2d(x, (2,2))\n",
        "        # x = F.relu(self.conv31(x))\n",
        "        # x = F.relu(self.conv32(x))\n",
        "        # x = F.relu(self.conv33(x))\n",
        "        # x = F.max_pool2d(x, (2,2))\n",
        "        # return x\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.convs(x1)\n",
        "\n",
        "        # Koch et al.\n",
        "        x1 = x1.view(-1, 256 * 6 * 6)\n",
        "        x1 = self.sigmoid(self.fc1(x1))\n",
        "\n",
        "        # VGG16\n",
        "        # x1 = x1.view(-1, 256 * 8 * 8)\n",
        "        # x1 = self.fc1(x1)\n",
        "        # x1 = self.sigmoid(self.fc2(x1))\n",
        "        \n",
        "        x2 = self.convs(x2)\n",
        "\n",
        "        # Koch et al.\n",
        "        x2 = x2.view(-1, 256 * 6 * 6)\n",
        "        x2 = self.sigmoid(self.fc1(x2))\n",
        "\n",
        "        # VGG16\n",
        "        # x2 = x2.view(-1, 256 * 8 * 8)\n",
        "        # x2 = self.fc1(x2)\n",
        "        # x2 = self.sigmoid(self.fc2(x2))\n",
        "\n",
        "        x = torch.abs(x1 - x2)\n",
        "        x = self.fcOut(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQu_OQQnEb_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "23f892f3-81a7-43e5-de43-4e8de910f262"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "siameseBaseLine = Net()\n",
        "siameseBaseLine = siameseBaseLine.to(device)\n",
        "\n",
        "def count_parameters(model):\n",
        "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f'The model architecture:\\n\\n', model)\n",
        "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
        "    \n",
        "count_parameters(siameseBaseLine)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model architecture:\n",
            "\n",
            " Net(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (conv3): Conv2d(128, 128, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(1, 1))\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (fcOut): Linear(in_features=4096, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "The model has 38,952,897 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4se7ZXHzEfcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
        "    if save_path==None:\n",
        "        return\n",
        "    save_path = save_path \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'optimizer_state_dict': optimizer.state_dict(),\n",
        "                  'val_loss': val_loss}\n",
        "\n",
        "    torch.save(state_dict, save_path)\n",
        "\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    save_path = f'siameseNet-batchnorm50.pt'\n",
        "    state_dict = torch.load(save_path)\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
        "    val_loss = state_dict['val_loss']\n",
        "    print(f'Model loaded from <== {save_path}')\n",
        "    \n",
        "    return val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHyEg0WbEh-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
        "    best_val_loss = float(\"Inf\") \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    cur_step = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        print(\"Starting epoch \" + str(epoch+1))\n",
        "        for img1, img2, labels in train_loader:\n",
        "            \n",
        "            # Forward\n",
        "            img1 = img1.to(device)\n",
        "            img2 = img2.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(img1, img2)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        val_running_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for img1, img2, labels in val_loader:\n",
        "                img1 = img1.to(device)\n",
        "                img2 = img2.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(img1, img2)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_running_loss += loss.item()\n",
        "        avg_val_loss = val_running_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}'\n",
        "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
        "    \n",
        "    print(\"Finished Training\")  \n",
        "    return train_losses, val_losses  \n",
        "\n",
        "# evaluation metrics\n",
        "def eval(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        print('Starting Iteration')\n",
        "        count = 0\n",
        "        for mainImg, imgSets, label in test_loader:\n",
        "            mainImg = mainImg.to(device)\n",
        "            predVal = 0\n",
        "            pred = -1\n",
        "            for i, testImg in enumerate(imgSets):\n",
        "                testImg = testImg.to(device)\n",
        "                output = model(mainImg, testImg)\n",
        "                if output > predVal:\n",
        "                    pred = i\n",
        "                    predVal = output\n",
        "            label = label.to(device)\n",
        "            if pred == label:\n",
        "                correct += 1\n",
        "            count += 1\n",
        "            if count % 20 == 0:\n",
        "                print(\"Current Count is: {}\".format(count))\n",
        "                print('Accuracy on n way: {}'.format(correct/count))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU093EYrEnMf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c1ddbfc-3b57-4252-e834-e2eb02d7b7a5"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(siameseBaseLine.parameters(), lr = 0.0006)\n",
        "num_epochs = 50\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "save_path = 'siameseNet-batchnorm50.pt'\n",
        "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1\n",
            "Epoch [1/50],Train Loss: 0.5328, Valid Loss: 0.45164161\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 2\n",
            "Epoch [2/50],Train Loss: 0.4203, Valid Loss: 0.43268060\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 3\n",
            "Epoch [3/50],Train Loss: 0.3682, Valid Loss: 0.34320883\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 4\n",
            "Epoch [4/50],Train Loss: 0.3257, Valid Loss: 0.30948794\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 5\n",
            "Epoch [5/50],Train Loss: 0.3137, Valid Loss: 0.32466590\n",
            "Starting epoch 6\n",
            "Epoch [6/50],Train Loss: 0.2908, Valid Loss: 0.28691168\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 7\n",
            "Epoch [7/50],Train Loss: 0.2808, Valid Loss: 0.26316745\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 8\n",
            "Epoch [8/50],Train Loss: 0.2524, Valid Loss: 0.23453234\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 9\n",
            "Epoch [9/50],Train Loss: 0.2561, Valid Loss: 0.23194509\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 10\n",
            "Epoch [10/50],Train Loss: 0.2452, Valid Loss: 0.24686054\n",
            "Starting epoch 11\n",
            "Epoch [11/50],Train Loss: 0.2292, Valid Loss: 0.23116273\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 12\n",
            "Epoch [12/50],Train Loss: 0.2246, Valid Loss: 0.20318072\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 13\n",
            "Epoch [13/50],Train Loss: 0.2169, Valid Loss: 0.20094474\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 14\n",
            "Epoch [14/50],Train Loss: 0.2110, Valid Loss: 0.18770619\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 15\n",
            "Epoch [15/50],Train Loss: 0.2092, Valid Loss: 0.20150618\n",
            "Starting epoch 16\n",
            "Epoch [16/50],Train Loss: 0.2007, Valid Loss: 0.20830574\n",
            "Starting epoch 17\n",
            "Epoch [17/50],Train Loss: 0.1970, Valid Loss: 0.18335998\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 18\n",
            "Epoch [18/50],Train Loss: 0.1845, Valid Loss: 0.18070732\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 19\n",
            "Epoch [19/50],Train Loss: 0.1792, Valid Loss: 0.18468090\n",
            "Starting epoch 20\n",
            "Epoch [20/50],Train Loss: 0.1921, Valid Loss: 0.17765282\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 21\n",
            "Epoch [21/50],Train Loss: 0.1640, Valid Loss: 0.15937157\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 22\n",
            "Epoch [22/50],Train Loss: 0.1732, Valid Loss: 0.16588197\n",
            "Starting epoch 23\n",
            "Epoch [23/50],Train Loss: 0.1750, Valid Loss: 0.16078322\n",
            "Starting epoch 24\n",
            "Epoch [24/50],Train Loss: 0.1717, Valid Loss: 0.15666999\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 25\n",
            "Epoch [25/50],Train Loss: 0.1620, Valid Loss: 0.24376174\n",
            "Starting epoch 26\n",
            "Epoch [26/50],Train Loss: 0.1627, Valid Loss: 0.16611183\n",
            "Starting epoch 27\n",
            "Epoch [27/50],Train Loss: 0.1535, Valid Loss: 0.14394029\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 28\n",
            "Epoch [28/50],Train Loss: 0.1440, Valid Loss: 0.14369868\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 29\n",
            "Epoch [29/50],Train Loss: 0.1573, Valid Loss: 0.14566257\n",
            "Starting epoch 30\n",
            "Epoch [30/50],Train Loss: 0.1458, Valid Loss: 0.15256447\n",
            "Starting epoch 31\n",
            "Epoch [31/50],Train Loss: 0.1404, Valid Loss: 0.13256377\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 32\n",
            "Epoch [32/50],Train Loss: 0.1375, Valid Loss: 0.13697439\n",
            "Starting epoch 33\n",
            "Epoch [33/50],Train Loss: 0.1463, Valid Loss: 0.21879604\n",
            "Starting epoch 34\n",
            "Epoch [34/50],Train Loss: 0.1451, Valid Loss: 0.13147607\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 35\n",
            "Epoch [35/50],Train Loss: 0.1413, Valid Loss: 0.13207224\n",
            "Starting epoch 36\n",
            "Epoch [36/50],Train Loss: 0.1371, Valid Loss: 0.12484885\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 37\n",
            "Epoch [37/50],Train Loss: 0.1300, Valid Loss: 0.12793913\n",
            "Starting epoch 38\n",
            "Epoch [38/50],Train Loss: 0.1286, Valid Loss: 0.10350993\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 39\n",
            "Epoch [39/50],Train Loss: 0.1306, Valid Loss: 0.11829141\n",
            "Starting epoch 40\n",
            "Epoch [40/50],Train Loss: 0.1238, Valid Loss: 0.10078614\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 41\n",
            "Epoch [41/50],Train Loss: 0.1254, Valid Loss: 0.12667910\n",
            "Starting epoch 42\n",
            "Epoch [42/50],Train Loss: 0.1233, Valid Loss: 0.11397607\n",
            "Starting epoch 43\n",
            "Epoch [43/50],Train Loss: 0.1230, Valid Loss: 0.19885040\n",
            "Starting epoch 44\n",
            "Epoch [44/50],Train Loss: 0.1204, Valid Loss: 0.10605310\n",
            "Starting epoch 45\n",
            "Epoch [45/50],Train Loss: 0.1075, Valid Loss: 0.12074893\n",
            "Starting epoch 46\n",
            "Epoch [46/50],Train Loss: 0.1128, Valid Loss: 0.10772187\n",
            "Starting epoch 47\n",
            "Epoch [47/50],Train Loss: 0.1094, Valid Loss: 0.10585813\n",
            "Starting epoch 48\n",
            "Epoch [48/50],Train Loss: 0.1129, Valid Loss: 0.09805024\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 49\n",
            "Epoch [49/50],Train Loss: 0.1113, Valid Loss: 0.09640446\n",
            "Model saved to ==> siameseNet-batchnorm50.pt\n",
            "Starting epoch 50\n",
            "Epoch [50/50],Train Loss: 0.0978, Valid Loss: 0.10575009\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O8Re1ZKErrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ef480ec-d0ef-4f0d-8c8e-c1896bf93506"
      },
      "source": [
        "import torch.optim as optim\n",
        "load_model = Net().to(device)\n",
        "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0006)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "eval_every = 1000\n",
        "total_step = len(train_loader)*num_epochs\n",
        "best_val_loss = load_checkpoint(load_model, load_optimizer)\n",
        "\n",
        "print(best_val_loss)\n",
        "eval(load_model, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded from <== siameseNet-batchnorm50.pt\n",
            "0.09640445820250888\n",
            "Starting Iteration\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VEPMfYUhDro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0753S2k6hJyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}